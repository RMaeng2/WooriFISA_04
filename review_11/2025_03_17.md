### 우리FISA 11주차 학습기록

#### ( 2025.03.17 ~ 2025.03.21 )

---

##### 2025.03.17. Mon

MLOps

docker-compose = 주문서 : 여기에 작성된대로 해줘~

Airflow
머신러닝의 어느기능에나 사용할수 있지만 데이터를 수집하고 전처리해서 떨궈주는데 많이 사용한다.
파이썬의 플라스크를 기반으로 만들어져 있다.

DAG단위로 작성하고 각각의 독립적인 태스크를 작성하고 이걸 이어서 작동할 수 있도록함

데이터가 작을 경우 중복이나 누락이 없도록 한꺼번에 복사하는 걸 권장 (full fresh)
매시간, 매일 바뀌는걸 업데이트 -> 비교할 수 있는 아이디 필요

멱등성
다른 서버에 의존해서 데이터를 주고 받는 경우가 많기 때문에 실패하게 되면 최종적으로 들어오는 데이터가 똑같은 결과를 보여줘야한다 .

원래 생태로 복

데이터 파이프라인의 입츌력에 관한 문서를 작성

배치 프로세스
주기적으로 일정시간 일정 간격마다 발생하도록 해두는 것
airflow 등장 전 : crontab -> 실패 시 재시도가 없다. 과거 실행 이력 보기 어려움

각 테스크 사이에 종료 코드를 설정하여 다음 실행 테스크의 순서가 달라진다.

배치성 테스크를 실행하기 위한 것이기 때문에 시간에 관한 모듈을 많이 불러왔다.

절대적 시간 말고 상대적인 시간을 할당할수 있도록
from import daysago
꼭 오늘 날짜 이전의 startdate는 있어야 한다.

통역기 - 어쩌구저쩌구Operator

#### airflow에서 제공하는 여러 기능들

**jinja {{ 변수명 }} Template**
변수명에는 airflow에서 제공하는 변수명이 들어감

**XCom**
각각 독립적인 테스크 사이에 데이터 전달을 위한 매커니즘
딕셔너리 형태로 값들을 전달
앞 task에서 push로 전달 그 다음 task에서 pull로 받음
retrun value를 저장
airflow 메타데이터 DB에 저장 -> 작은 데이터만 저장하는 것이 좋다.
민감한 정보를 저장하지 않는 것이 안전하다.
자동화된 키가 return value에 자동 저장

- Operator : DAG에 담긴 각각의 단일 작업을 수행
- Task : 오퍼레이터 작업의 관리를 하기위한 컴포넌트

**operator**
MySQLOperator
데이터베이스 서버에 접속할 때는 데이터베이스의 스키마까지 적어줘야하고 데이터베이스 내에서 스키마를 꼭 만들어줘야한다.

### MLOps에서의 airflow 사용

**주기적인 실행**이 필요한경우
batch Training : 주기적인 모델 학습
batch serving(inferance) : 주기적인 인퍼런스

---

#### 우리FISA 47일차 KPT

Keep : 수업 집중 및 이해도 좋은 편이었으나 오후에는 많이 흐트러짐

Problem : 별로 안됐지만 오늘 수업 필기를 날렸다.

Try : 저장을 습관화하고 삭제 전에 확인하기
