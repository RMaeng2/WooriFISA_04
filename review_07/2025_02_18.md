### 우리FISA 7주차 학습기록
#### ( 2025.02.17 ~ 2025.02.21 )
***
##### 2025.02.18. Tue
머신러닝, 딥러닝 학습

기존 데이터를 어떤 알고리즘으로 학습할지 결정하여 패턴을 생성하거나 예측한다.
기존 프로그래밍 - 개발자 직접 코딩
머신러닝 - 모델 스스로 패턴 학습

입력값 : 독립변수(x) - 자기 자신은 영향 X
출력값 : 종속변수(y) - 독립변수에 영향을 받아 값이 변함

목표 : 아예 처음보는 x를 가지고 y를 맞추는 것
(일반화된 결과치를 높이는 것 / 일반화란? 새로운 데이터에서도 높은 정확도를 내는 것)
훈련 과정 : 지금까지 쌓아온 x와 y의 쌍을 넘겨주는 것

🚨 훈련 데이터에만 최적화되는 과대적합(Overfitting) 주의

배치 : 데이터를 몇 개씩 잘라서 학습할지
에포크(epoch) : 전체 데이터 셋에 대해 한번의 학습과정을 완료하는 기준
학습률 : 최적을 값을 찾기 위해 가중치를 업데이트 할 때 이동거리를 조절
ex. 전체 데이터셋의 개수가 80개, 배치크기 16장이면 한 에포크동안 5번 학습 (16*5 -> 1 epoch)
80장중 일부 20%는 테스트 데이터로 사용하기 위해 빼놓고 사용
훈련 데이터 64장으로 모델 학습, 테스트 데이터 16장으로 모델 정확도 평가

1. 데이터 수집
2. 데이터 전처리
3. 데이터 분할
훈련 데이터 (80%) / 테스트 데이터 (20%)
과대적합을 막기 위한 테스트 데이터 필요
4. 모델학습
훈련데이터를 통해 모델 학습
5. 모델평가
테스트 데이터를 통해 모델 평가
평가 지표 : 정확도(Accuracy) - 예측이 얼만큼 맞는가 / 오차(MSE, MAE) - 예측값과 실제값 차이
정확도가 커지면 손실은 작아진다.
6. 모델 최적화
학습률, 배치 크기 등 하이퍼파라미터를 조절
드롭아웃, 정규화 사용
7. 모델 배포

**< 실습 >**
Teachable Machine 사이트와 Streamlit을 이용하여 모델을 학습하고 배포하기

---- 여기까지

경사하강법
한 에폭이 돌 때마다 


클러스터링

비지도학습
많은 문장들의 관계를 파악해서 행렬로 줄여 학습하는 행렬축소

다수결에 의한 결과를 출력하는 앙상블러닝

퍼셉트론 

사람이 개입하는가 안하는가
학습 및 로그 데이터를 바로 반영하는가 안하는가(온라인/오프라인 학습)


#

***
#### 우리FISA 30일차 KPT

- Keep: 잘 했기 때문에 유지하고 싶은 것
    1. 
    2. 

<br>

- Problem: 어려움을 느껴 개선하고 싶은 것
    1. 
    2. 

<br>

- Try: 구체적으로 시도할 내용
    1. 
    2. 