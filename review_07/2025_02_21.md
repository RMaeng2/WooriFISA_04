### 우리FISA 7주차 학습기록
#### ( 2025.02.17 ~ 2025.02.21 )
***
##### 2025.02.21. Fri

#### 서포트 벡터 머신
보조 알고리즘을 활용해서 결정경계를 깔끔하게 만들어주는 머신
데이터 포인트들의 정중앙에서 경계를 긋도록!

규제는 결국 현재의 기울기에 적용하는 힘
현재 기울기에서 다음번 기울기로 가는 유동성을 높이게 된다.
→ 기울기가 빠르게 데이터 포인트들에 영향을 받는다!

기울기가 0이 상태로 시작해서 변화하게 된다.

- 장점
서포트벡터머신에 새로운 차원의 초평면을 만들고 경계를 만들게 하면 비선형 경계를 만들 수 있게 된다.


감마 : 새로운 데이터 쪽으로 잡아끄는 힘
들어오는 각각 데이터 포인트들이 현재의 가중치와 바이어스를 변경하는데 영향을 더 미치도록 

#### 결정 트리 알고리즘
자기 안에서 서로 반반이 되는 관계를 찾아 나간다.
하나의 특성 안에서 불순도가 0이 될 정도로 depth를 타고 나간다.
특징 : 자기 안에서 나눠지는 것이기 때문에 가지의 깊이나 가지치기 횟수를 정해주어야 한다.(과대적합을 막기 위해)
기본적으로는 반반으로 나눌 수 있는 최적의 알고리즘을 찾는 것에서 시작하기 때문에 최초 실행할 때 무작위성이 높을 수 있다.
하지만 설명력이 가장 높고 높은 정확도 때문에 의사결정에 많이 사용된다.



어떻게 나누어야 깔끔한 하이퍼 플레임인가?
결정 경계가 어떤게 깔끔한 건지 판별

근처에 있는 데이터 포인트를 계산을 하고 가장 가까운 데이터포인트들의 거리를 절반으로 나눈다.

#### KNN (거리기반 알고리즘)

동점인 경우에는 그룹을 판단할 수 없으므로 홀수개로 설정해주어야한다.


#### 모델의 성능 측정 방법
모든 모델에는 score() 내장
전체 개수 중에 잘못분류하지 않은 것들을 세서 정확도(accuracy) 측정


#### K-Fold 교차 검증
데이터를 K개의 폴더로 나누고 K번 학습을 반복하면서 K개의 평가점수를 얻는다. 이 평가점수들의 평균을 내어 모델의 성능을 평가

하이퍼 파라미터 : n_split, suffle

**교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에 하기**
paramgird

**학습/검증 레이블 데이터 값의 분포도 확인후 불균형 분포 해결**

split() 시에는 target(종속변수,label,class)의 정보도 반드시 적용!!!

아이리스 데이터를 분류하기에 가장 좋아보이는 파라미터 찾아보기


.score 분류모델의 성능을 평가할 수 있는 평가지표가 내장되어있다.


#### 분류모델 성능 평가
정확도 (제 1지표로 보는 모델들이 많다.)
정밀도 (참으로 분류한 것 중에 진짜 참)
재현율 (진짜 참인 것들 중에서 참이라고 판단한 비율, 얼마나 놓쳤는지 판단하기 위해 제 2지표로 사용)
하나라도 놓치면 큰일 (ex. 암인데 암이 아니라고 한다면..?)

predict_proba라는 메서드가 있는 알고리즘만 threshold를 조절 가능 - LR, RFC(Random Forest Classify), TREE


정확도는 참을 참 + 거짓을 거짓 / 모든 값 -> 불균형한 데이터에서는 괜찮은 지표라고 볼 수 없다.


***
#### 우리FISA 34일차 KPT