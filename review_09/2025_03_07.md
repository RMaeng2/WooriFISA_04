### 우리FISA 9주차 학습기록
#### ( 2025.03.04 ~ 2025.03.07 )
***
##### 2025.03.07. Fri

Softmax 함수
다중 클래스 분류 문제에서 확률 값을 출력할 때 사용하는 활성화 함수야.
쉽게 말해서, 모델이 각 클래스에 속할 확률을 계산하는 함수

출력값을 확률(0~1)로 변환해서 모든 클래스의 확률 합이 1이 된다.
→ 즉, "이 데이터가 어떤 클래스에 속할 확률"을 알 수 있다.



스탠다드 스케일링과 노멀라이제이션 후 비교



torch.bucketize(df['Model Year'].values, boundaries, right=True)
- `right=True`?

one hot encoding!

가중치 초기화

자비에르
총 뉴런을 가지고비 비율을 고려해서 가중치와 바이어스를 할당


허
지금 층에 있는 노드를 기준으로 하여 평균과 분산을 흩뿌려줘요

uniform
평균 0, 분산 0.01에서 가중치들을 흩뿌려줘요

normal
정규분포를 따르도록 평균과 분산을 모든 뉴런에 대해서 할당해요

모델을 만들면 좋은결과 근처로 수렴을 한다 .학습을 오래 시키면 결과 좋아져요 근데 그 결과까지 가는 시간이 줄어들기 때문에 가중치 초기화를 하는것입니다~

카이밍 허
자기층에 있는 뉴런으 ㅣ개수들만 가중치와 바이어스를 할당


파이토치로 모델학습하는 과정
1. 모델 정의
2. 데이터셋
3. 데이터 로더에서 데이터를 흘려보내면서 학습~!(tensor로 형변환)


train() - 가중치와 바이어스를 업데이트해
eval() - 가중치 다 꺼놔

normalization을 컬럼별로 해줬는데 딥러닝은 알아서해라~
-> 행별로 정규화

평균과 분산이 달라서 생기는 영향력을 줄이기 위한 것이다.


***
#### 우리FISA 43일차 KPT