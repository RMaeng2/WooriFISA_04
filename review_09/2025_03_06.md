### 우리FISA 9주차 학습기록
#### ( 2025.03.04 ~ 2025.03.07 )
***
##### 2025.03.06. Thu



#### Optimizer

한 에폭마다 가중치를 변경 : 경사하강법 GD
스텝 방향에 더 중점을 둔 모멘텀


다중분류 - crossentropyloss로 측정


모델 저장
pt, pth의 확장자 주로 사용


#### PyTorch
- PyTorch에서 딥러닝을 사용하는 이유는 Tensor로 형변환해서 빠른 계산이 가능하기 때문
- Tensor는 NumPy 배열보다 빠르고 효율적인 연산이 가능
- GPU 연산(CUDA)을 지원해서 훨씬 빠르게 연산
- PyTorch의 자동 미분 기능(AutoGrad) 덕분에 기울기(Gradient) 계산도 자동화 가능

(1) 모델 정의
신경망의 구조를 정함 (nn.Linear(), nn.ReLU()등 사용)

(2) 데이터셋 준비
Dataset 클래스를 상속해서 커스텀 데이터셋을 만들거나, PyTorch 내장 데이터셋(MNIST, CIFAR-10 등) 사용

(3) 데이터 로더(DataLoader) 사용
미니배치 학습을 위해 데이터를 나누는 역할
shuffle=True로 설정하면 데이터를 섞어서 랜덤하게 배치 생성

미니배치는 전체 데이터를 한 번에 학습하지 않고, 작은 묶음(배치)으로 나누어 학습하는 방법
장점 : 메모리 성능 향상, 훈련 속도 향상, 일정 수준의 랜덤성 유지

(4) 모델 학습(Training)
데이터 로더를 통해 데이터를 모델에 흘려보내면서 학습함 (순전파, 손실 계산, 역전파, 가중치 업데이트)
optimizer.zero_grad(): 이전 기울기 초기화 (안 하면 기울기 누적됨)

>**손실 함수(Loss Function)**
모델이 얼마나 틀렸는지 평가하는 함수
이진 분류 → BCELoss(), 다중 분류 → CrossEntropyLoss(), 회귀 → MSELoss()


>**역전파(Backpropagation) & 최적화(Optimization)**
역전파: loss.backward()를 호출하면 기울기(gradient)를 자동으로 계산
옵티마이저: Adam, SGD 등을 사용하여 가중치 업데이트

>**GPU 사용 (.to(device))**
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device), tensor.to(device) 하면 GPU에서 학습 가능

- 모델 구현시 init과 forward 함수를 꼭 정의해줘야하는 이유

1️⃣ __init__() 함수의 역할
신경망(딥러닝 모델)의 "구조"를 정의하는 부분
즉, 레이어(layer) 를 정의하는 곳

2️⃣ forward() 함수의 역할
데이터가 모델을 통과할 때, 어떤 연산을 할지 정의하는 곳
즉, 순전파(Forward Propagation) 를 설정하는 곳

- __init__() 없이 만들면 레이어가 정의되지 않아서 오류 발생
- forward() 없이 만들면 PyTorch가 순전파(Forward)를 실행할 방법이 없음
- forward()가 있어야 자동 미분(autograd)이 가능하고, 모델을 훈련할 수 있음!


TP, FP, TN, FN의 의미
|실제 값|	모델 예측	|설명|
|---|---|---|
|✅ True Positive (TP)|	Positive (예: 스팸)|	실제 스팸을 스팸이라고 맞게 예측
|❌ False Positive (FP)	|Positive (예: 스팸)|	정상 메일을 스팸으로 잘못 예측 (오탐, False Alarm)|
|✅ True Negative (TN)|	Negative (예: 정상 메일)|	정상 메일을 정상이라고 맞게 예측|
|❌ False Negative (FN)|	Negative (예: 정상 메일)|	실제 스팸인데 정상이라고 잘못 예측 (누락, Miss)|


TP, FP, TN, FN과 평가 지표 관계
|평가 지표|	수식	|의미| 설명 |
|---|---|---|---|
|Accuracy (정확도)|	(TP + TN) / (전체)	|전체 예측에서 맞춘 비율| 전체 데이터 중에서 맞게 예측한 비율 |
|Precision (정밀도)|	TP / (TP + FP)	|스팸이라고 예측한 것 중 실제 스팸 비율 (FP 줄이기)| 정답이라고 예측한 것들 중에서 실제로 정답인 비율 |
|Recall (재현율)|	TP / (TP + FN)	|실제 스팸 중에서 예측이 맞은 비율 (FN 줄이기)| 실제 정답 중에서 맞게 예측한 비율 |
|F1-score|	2 × (Precision × Recall) / (Precision + Recall) |	Precision과 Recall의 균형 |F1-score = 2 * (Precision * Recall) / (Precision + Recall)|



✔ TP (True Positive) = 맞게 예측한 정답
✔ TN (True Negative) = 맞게 예측한 오답
✔ FP (False Positive) = "오탐" → 정상인데 스팸으로 예측
✔ FN (False Negative) = "누락" → 스팸인데 정상으로 예측

💡 Precision: 오탐(FP)을 줄이는 것이 중요할 때
💡 Recall: 놓침(FN)을 줄이는 것이 중요할 때


***
#### 우리FISA 42일차 KPT